= NATS events and beyond
:revdate: 2022-09-26
:imagesdir: images
//:title-slide-transition: zoom
:title-slide-transition-speed: fast
//:customcss: fragments.css
:revealjs_hash: true
:revealjs_center: false
:revealjs_height: 1080
:revealjs_width: 1920
:icons: font
:font-awesome-version: 5.14.0
:revealjs_controls: true
:revealjs_controlsTutorial: true
:revealjs_totalTime: 2700
:revealjsdir: ./reveal.js

Introduction for developers

by Harupa Dzmitry <d.harupa@pin-up.team>

@{localyear}

[.notes]
--
Это 1-я часть серии докладов посвященной НАТСУ

ВАЖНО: https://t.me/GolangPresentationBot все должны зайти по ссылке и зарегистрироваться через корпоритивную почту

На протяжении доклада я буду прерываться на 1 минут, для запуска квиз.

Прошу относится к голосованию серьезно!
--

[%notitle]
== Quiz

Quiz

[.columns]
== About author

[.column]
--
* >13 years in development
* >6 years as Go lang dev
* >5 in Gambling industry (Game dev, Producer, Game Master, Mathematician)
* Developed 4 games for Booongo (as partners)
* Performed 5 game maths for IGT
* Certified Kubernetes Application Developer
* For now solution architect in Pin-Up company
--

[.column]
--
image::AVA.jpg[]
--

[autoslide=60000]
== Agenda

- NATS
* Overview
* Quality of service
- NATS concept
* Subject-Based Messaging
* Core
- Q/A

[NOTE.speaker]
--
Мы пройдемся по высокоуровнему дизайну натсу и его ключевым особенностям - CORE

Рассмотрим основные концепции MQ и рассмотрим что нового нам готовят новые версии НАТС.

В конце доклада у нас будет 15 минут на ваши вопросы. Я буду стараться уложиться в 45 минут!
--

[autoslide=120000]
== NATS
> message oriented middleware

[NOTE]
.With NATS, application developers can
====
* Effortlessly build distributed and scalable client-server applications.
* Store and distribute data in realtime in a general manner. This can flexibly be achieved across various environments, languages, cloud providers and on-premises systems.
====

[NOTE.speaker]
--
Сами разработчики называют NATS: `сообщения-ориентированным посредником` и я думаю, после того как мы углубимся в теорию вы с этим согласитесь

На высоком уровне натс решает несколько зщадачь:

* Возможно разрабатывать без особого труда распределенные и масштабируемые клиент-сервер приложения
* Хранить и распространять данные в реальном времени в общем виде

INFO: TELEGRAM VOTE
--

[autoslide=120000]
=== What do you use NATS for?
You can use NATS to exchange information with and make requests to other applications.
You can also use NATS to make your application into a distributed peer-to-peer application.

At a high level your application can use NATS to:

* Send (Publish) information to other applications or instances of your application.
* Receive (Subscribe) information (in real-time or whenever your application runs) from other applications or instances of your application.
* Make a request to a server or the service provided by another application.
* Store shared (consistent) state/data between other applications or instances of your application.
* Be informed in real-time about any new data being sent, or any changes to the shared state/data.

[.notes]
--
Для чего мы можем использовать НАТС?

Конечно же для обмена информацией и запросов с другими приложениями а  так же строить распределенные приложения.

На высоком уровне наши приложения могут:

* отправлять информацию другим приложениям или экзэмплярам нашего приложения.
* в реальном времени или во время работы приложения получать сообщения от других приложений или экземлпяров нашего приложения.
(Обратите внимание, что экземпляры - говорит о распределении внутри собсвенного сервиса, когда 1 приложение обшается между своими репликами, хотя я предпочитаю придерживаться практик 12 факторного приложения и использовать WORKER подход, хотя это и есть другой инстанс так же :)
* Точно так же мы моежем использовать RPC подход.
* Хранить общие (и постоянные) состояние или данные между другими приложениями или экземплярами нашего.
* Получать нотифиации об изменениях общих данных или состояний.

INFO: TELEGRAM VOTE
--

[autoslide=120000]
=== Don't worry
* Who sends the information that you want to receive.
* Who  is interested in the information you are sending to others, or how many are interested or where they are.
//* Where the service you are sending a request to is located, or how many currently active instances of that service there are.
* How many partitions or servers there are in the cluster.
* Security (just identify yourself).
* Whether your application is up and running at the time the information is sent or not (using JetStream).
* Flow control (using JetStream)
* QoS flexibility
* Fault-tolerance
* The topology of the NATS server infrastructure or it is architected.

[.notes]
--
Разработчики предлагают ряд консернов о которых нам предлагают забыть при разработке приложений

* Отправителя агностик - не важно кто отправляет информацию которая вам нужна. Нас не ваолнует где это сервис находится, какой его адрес, какой порт подключения...
* Получателя агностик - нам не важно кто наши читатели, сколько их и откуда они подуключились.
* А вот сколько партиций у кластера, все таки это уже устаревший консерн. Тут нас уже волнует какой уровень репликации данных мы хотим использовать.
* О безопасности, только идентифицируй себя. NATS крайне сильный и обеспокоен безопасностью и поддерживает все необходимое, что бы обезопасить инфраструктуру.
* Нас не беспокоит даже находятся ли сервисы в онлайне в данный момент времени (JetStream)
* Мы получаем право выбирать какоу уровень гарантий качества нам неоходим изходя из наших потребностей.
* Отказоустойчивость
* Отказ от безпокойства за топологию это интересный момент, т.к. есть определенные неюансы, но на высоком уровне - вы можете отправлять сообщения в любом EDGE локации и ваше сообщение найдет адресата даже через сеть кластеров.

INFO: TELEGRAM VOTE
--

//[autoslide=30000]
== Overview
* Functionality
* Connectivity
* Deployment Architectures
* Security

[.notes]
--
Пройдемся по ключевому функционалу
--

[autoslide=120000]
=== Functionality

* Core
* JetStream

WARNING: Streaming STAN protocol is  ***Obsolete*** and often appear as legacy documentation page for some developers google offers

[.notes]
--
С точки зрения функциональных возможностей следует разделять ЯДРО и JetStream.

Раньше был еще STAN протокол, который стремился повысить уровень гарантий доставки. Это протокол оказался не таким удачным и команда поспешила заменить его более надежным RAFT протоколом.
Когда мы говорим о стриминге, мы де-факто имеем ввиду JetStream! Прошу это помнить!

Ядро - представляет базовый функционал, который изначально был разработал и за что мы все полюбили NATS

Джет Стриминг - новый функционал, который расширил возможности, дав нам альтернативу Apache Kafka, которую в первую очередь крайне легко поддерживать и обслуживать.
--

[autoslide=30000]
=== Connectivity footnote:[https://docs.nats.io/nats-concepts/connectivity]

* NATS plain
* TLS encrypted NATS connections
* MQTT footnote:MQTT[https://docs.nats.io/running-a-nats-service/configuration/mqtt]
* WebSocket footnote:WebSocket[https://docs.nats.io/running-a-nats-service/configuration/websocket]

[.notes]
--
Подключиться к NATS можно по обычному или защищенному TLS подключению, а так же MQTT протокол широко распространенный в IoT решениях и WebSocket, который в своем представлении не нуждается.
--

//[autoslide=120000]
=== Deployment Architectures footnote:[https://docs.nats.io/nats-concepts/service_infrastructure/adaptive_edge_deployment]
* Single
* Cluster footnote:Cluster[https://docs.nats.io/running-a-nats-service/configuration/clustering]
* Super-cluster
** Gateway cluster propagation protocol footnote:Gatewat[https://docs.nats.io/running-a-nats-service/configuration/gateways]
** Leaf message propagation Protocol footnote:Leaf[https://docs.nats.io/running-a-nats-service/configuration/leafnodes]

[.notes]
--
Как способ разворачивания, может быть развернута как `single node`, что не HA, в режиме кластера, сурер-кластер GateWay и Leaf протокол, который мы выбрали для построения нашего супер-кластера.

* Single - исключительно дев. окружение самого разработчика
* Cluster - HA deployment, обычно с 3я нодами, повышает доступность и пропускную способность
* Super-cluster
** Gateway - обьединяет несколько кластеров в полную сетку. Кластеры используются для обьединения node, в то время GW - для обьединения кластеров. Архитектурная цель протокола: Disaster Recovery
** Leaf - расширяет существующую NATS систему в любом размере. Прозрачно перенаправляют сообщения с локальных клиентво к одной или больше удаленным системам и обратно.
--

//[autoslide=240000]
=== Security footnote:Authentication[https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro]

* Token
* User/Password
* TLS auth
* NKeys
* JWT

[.notes]
--
Прежде чем говорить о акаунтах пользователей, нужно немного разобраться о роли Акаунта и Пользователя.

Важно понимать разницу между аккаунтои и пользователь.

Аккаунт - это просто субсет пользователей с рязом высокоуровневых различий.

> Accounts allow the grouping of clients, isolating them from clients in other accounts, thus enabling multi-tenancy in the server. With accounts, the subject space is not globally shared, greatly simplifying the messaging environment. Instead of devising complicated subject name carving patterns, clients can use short subjects without explicit authorization rules. System Events are an example of this isolation at work.

Различия - системный или обычный.

Системный аккаунт - акаунт мониторинга и репортинга, в то время обычный - это работчая группа, куда разработчики и подключаются

Так же аккаунт обязательно должен иметь включенную опцию *jetstream*, без нее все пользователи будут использовать только CORE функционал

IMPORTANT: Jetstream аккаунт не может быть системным.

У нас принята конвенция использовать 2 вида аккаунтов: `SYS` и `ACC`

Про методы аутентификации:

.Token
Это единый токен для подключения. Для авторизации используется поле `user` у пользователя нет ограничений, но он принадлежит не системному аккаунту.

.User/Password
Тут все просто. Это очень удобный механизм, т.к. позволяет легко настраивать права выбранных пользователей. Каждый пользователь может быть изолирован даже по типу подключения:

.TLS auth
Клиент предоставляет сертификат подписанный рутовым сертификатом установленным конкретному кластеру. Мапинг пользователей осуществялется через данные указанные при регистрации пользователя.

> Subject Alternative Name (SAN) maps to a user. It will search all email addresses first, then all DNS names. If no user could be found, it will try the certificate subject.

[source]
----
Certificate:
...
        X509v3 extensions:
            X509v3 Subject Alternative Name:
                DNS:localhost, IP Address:0:0:0:0:0:0:0:1, email:email@localhost
            X509v3 Extended Key Usage:
                TLS Web Client Authentication
...
----

Можно использовать RFC 2253 Distinguished Names (распределенные имена)  синтаксис описать пользователя относящегося с предметом сервтификата
[source,yaml]
----
authorization {
  users = [
    {user: "OU=testuser@MacBook-Pro.local (Test User),O=mkcert development certificate"}
  ]
}
----

.NKeys
Современная система публичной сигнатуры ключа основанной на Ed25519. Позволяет идентифицировать пользователя без хранения или видения приватного ключа.

Настраивается намного легче, т.к. на сервере мы указываем публичный хэш ключа и далее его уже привязываем к группе прав.

Тут по прежнему нам нужен приватный ключ для клиента, но на стороне сервера - только приватный ключ, что упрощает обслуживание.

.JWT
Открытый стандарт RFC7519 метод для безопасного предоставления запросов между двумя распределенными частями.

Подпись осуществляется через Ed25519 алгоритм. Все `Issuer` и `Subject` поля ключи - публичные NKEY которые.

`Issuer` и `Subject` - залинкованы на  следующие роли:

* Operators
* Accounts
* Users
--

[%notitle]
== Quiz

Quiz

[autoslide=120000]
== Quality of service (QoS) footnote:[https://docs.nats.io/nats-concepts/what-is-nats] footnote:[https://developers.cloudflare.com/pub-sub/learning/delivery-guarantees]

A.K.A: Delivery guarantees or “delivery modes”

https://docs.nats.io/nats-concepts/overview/compare-nats[NATS comparison]

Developer should be aware about quality of delivery between NATS components to achieve desired goal.

[cols=3,frame=sides,options=header]
|===
| QoS
| NATS component
| Better for

| At most once, QoS(0)
| Core NATS
| Inviable data, events quickly superseded or high rate messaging

| At-least, QoS(1)
| JetStream (Stream+Consumer configuration)
| Transaction processing, most forms of chat messaging, and remote command processing

| Exactly once, QoS(2)
| JetStream: Producer: Message Deduplication Consumer: double ask
| Subscribers must receive the message only once.

|===

Also always build additional reliability into your client applications yourself with proven and scalable reference designs such as acks and sequence numbers.

[.notes]
--
[NOTE]
Определяет как сильно MQ обрабатывает доставку сообщений. Каждый уровень гарантии это своеобразный компромис между скоростью и уверенностью в обработанном сообщении.
С каждым уровнем система требует больших проверкок и подтверждений для гарантии, что сообщение было обработано.
Что влияет на пропусную способность.

Понимание гарантии доставки крайне важные при проектировани IPC. И может выбирать между пропускной способность или гарантией отправки сообщения.

WARNING: Команда разработчиков должна понимать разницу и уметь правильно выбрать необходимый уровень качества доставки.

Для принятия решения важно анализировать бизнес требования функционала:

1. Насколько ценно сообщение?
2. Можем мы его потерять?
3. Что делать когда сообщение было утеряно?
4. Каие действия при системных ошибках следует предпринимать отправителю и/или подписчику?

.At most once (QoS 0)
В лучшем случае - отправит. Клиент не может знать хоть кто-то прочитает сообщение или нет! Еще называется “best-effort”

Если никто не слушает subject или не активен в момент отправки сообщения - сообщение не будет доставлено.

Такой же уровень гарантии предоставляет TCP/IP.

Ядро отправляет и забывает сообщение. Он держит сообщения только в памяти и никогда не сохраняет их на диск.

Обладает высокой пропускной способностью, т.к. накладные расходы это пропускная способность сети и CPU системы.

.At-least once (QoS 1)
Клиент получает гарантию, что его сообщение будет сохранено.
На этом уровне гарантии клиент получает больше возможностей для отслеживания состояния его сообщения: если сообщение не будет отправлено он будет знать, что сообщение не было сохранено в стрим стор и нужно предпринять меры.

.exactly once QoS (QoS 2)
Ideal when message rates are fairly low and where latency is not a primary concern.
--

[%notitle]
== Quiz

Quiz

[autoslide=60000]
== NATS concept
* Subject-Based Messaging
* Core
* JetStream
* Subject Mapping and Partitioning

[.notes]
--
Давайте поговорим об овновных концепта НАТС:

* концепт subject
* КОР функционале
* стриминг системе
* ии subject маршрутизации и пепееаправлении, это функцонал v2.9 патча и к сожалению мы его не сможем покрыть
--

[autoslide=120000]
== Subject-Based Messaging
`Subject` - fundamental entity of NATS at all. In `Kafka`, `NSQ`, `RabbitMQ` - "topic" naming convention is used.

image:msgsvg2.svg[]

Represent case seinsitive string with one or more words `[a-zA-Z]`  with dot ('.')  separator.

One more thing - where is *Wilecards*: "*" or ">"

[.notes]
--
Тема/Обьект/Subject - фундаментальная сущьность NATS. В Кафке, NSQ или RabbitMQ - имеет имя "topic"

Представляет собой строку, слова в которой разделены точкой. Важно, что САБЖ чувствителен к регистру и состоит из букв и цифр.

Слова САБЖА разделенные точкой создают своеобразную иерархию.

Важную роль играют сец. символы - *** и *>*

* - заменяет только одно слово, в то время > - заменяет все правее ее, и находится в конце, обычно. > можно использовать,
к примеру, как систему мониторинга или аудита безопасности. Если подписаться на САБЖ включаюзщий только > можно получать все сообщения из системы.
Это можно обойти системой ограничений.

Спец. символы могут встречаться несколько раз `*.*.east.>`

Обратите внимание на пример, он хорошо показывает кто из подписчиков получает сообщение[30 sec timeout]
--

//[autoslide=60000]
== Core
Basic functionality which provide StateLess functionality with QoS tear 0 -  *At most once*

* Publish-Subscribe
* Request-Reply
* Queue Groups

[.notes]
****
Я хочу сразу оговорить, что есть CORE функционал и это легаси часть NATS вполне жизнеспособна т.к. дает нам *AT most once* гарантию доставки.
Ей не нужно дисковое хранилище, она крайне быстра т.к. все что нужно ей это в момент получения запроса отправить всем кто подписан сообщение.

С JetStream появилось несколько особенностей архитектуры, с которой многие разработчики путаются. И мне хочется закрыть это недопонимания.

Важно понимать, что JetStream расширяет возможности NATS новым функционалом и это решать разработчику, какой именно механизм ему стоит исползовать.
****

[autoslide=60000]
=== Publish-Subscribe footnote:[https://www.youtube.com/watch?v=jLTVhP08Tq0]

NATS implements a publish-subscribe message distribution model for one-to-many (Fan-Out) communication.

image:pub-sub.svg[]

.Message
1. subject
2. payload
3. headers
4. reply (opt)

Message size: *1Mb* by default, recommend up to *8Mb*, can be increased to *64Mb*

[.notes]
--
Класическая модель Pub-Sub реализовывает модель распределения - Один ко многим, так же это архитектурный патерн - Fan-Out.

Каждый кто подписан на сообщение и находится в подключенном состоянии получит сообщение.

Важно помнить о размере сообщения, которое по умолчанию имеет ограничение 1Мб, и которое можно расширить до 64, но рекомендуется не больше 8.

Самый на мое усмотрение элемент сообщения - Headers, которые появились в v2.2 и дали возможность использова трасировку,
без обязательного помещения информации в тело сообщения. Так же, опциональное поле - reply позволяет написать свою реализацию *Request/Reply* функционала.
--

//[autoslide=180000]
=== Request-Reply
Request/Reply approach - Remote procedure call (RPC) via MQ NATS system. This mean it's blocking operation based on pub-sub functionality.

image:req_reply.svg[]

* Publisher put `INBOX` tmp subject into reply field with further waiting respond on it

IMPORTANT: Producers should use *drain before exiting* processing for waiting unanswered messages

[WARNING]
====
Remember One-to-Many. This mean all subscriber will get this message. In horizontal scale it can bring to unpredictable behaviour
====

[.notes]
--
У меня этот функционал вызывает спорные чувства.

С одной стороны это Киллер Фича.

Она решает волпросы сервис-дискавери системы, легка в использовании, не требует массы другого функционала для балансировки как в класических протоколах RPC.

Я даже считаю, что использование NATS как-то даже повлияло на его феноменальный рост.

Но с точки зрения архитектуры - это MQ система, и реализаций - сахарное решение и нужно даже сказать, довольно интересное.

Для PIN-UP может даже оказаться, что эта система станет чуть-ли не основной :) Сейчас мы работаем еще над одной системой, которая должна нам дать и сервис-дискавери, и возможность балансироваки http, grpc между сервисам - и это не K8S, над которым мы так же работаем :)

НО, давайте посмотрим как же работает Request/Reply:

Это блокирующая операцию, которая задейсвует подписчиком сперва отправку сообщения и далее - подписку на сообщение, которое он поместил в поле REPLY.

Есть важные моменты:

* Продюсер должен реализовать в обязательном порядке - drain логику

которая просто будет ждать какое-то время все незакрытые хэндлеры. Это особо важно в наших немасштабируемых и in-memory processing системах. Т.к. время дрэйна может быть недостаточно при 100500 рутингах

* Еще важная проблема - это несовсем четкая документация, которая с одной стороны призывает к легкой масштабируемости -

мол, не парьтесь, система через динамические очереди может гарантировать, что 1 сообщение получит только одно подключение.
И в тоже время, хвастается на то, что запрос могут обрабатывать несколько подписчиков.

Тут многие могут запутаться.

По умолчанию, это так и работает - правило ОДИН-КО-МНОГИМ тут так же работает, никто его не отменял. Поэтому замасштабированные подписчики ВСЕ получат запрос реплики, это может привести к МИЛЛИОНУ проблем.

По этому важно, понимать все возможности NATS и как их использовать!

НАДЕЮСЬ я тут вас уже заинтересовал и вам уже интересно!

> Поднимите руку, кто знает, как решить вопрос с гарантией ОДИН-К-ОДНОМУ ?
--

[%notitle]
== Quiz

Quiz

//[autoslide=120000]
=== Queue Groups footnote:[https://docs.nats.io/nats-concepts/core-nats/queue]
Combine one or more consumer into group (like Load Balancer) where only one random member get a message. Group have the same naming convention as subject.

IMPORTANT: Queue subscribers are ideal for scaling services.

image:groups.svg[]

NOTE: RabbitMQ, Kafka has the same naming concept - "queue" while NSQ - "chanel"

[.notes]
--
Семантически группа - имеет такое же название в RabbitMQ и Kafka. Хотя в NSQ имеет имя - channel.

Она комбинирует один или более подписчиков в единую группу, так называемый лоад балансер. Сама группа имеет те же требования к неймингу, что и subject.

Груповая очередь - важный функционал для микро-сервиса. Без нее невозможно реализовать горизонтальное масштабирование.

Т.к. обычная бизнес задача сервиса - обрабатывать разово каждое пришедшее в сервис сообщения.

А мы уже знаем, что по умолчанию модель доставки ОДИН-КО-МНОГИМ.

Но наш сервис должен быть масштабируемым!!!

Разработчик при подписке должен четко понимать какое требуется поведение его приложение при масштабировании!

Непонимание этого приведет к КАТАСТРОФИЧЕСКИМ последсвиям, особенно в промышленной среде, когда репликация может быть расширена и на 20 и больше копий,
в то время как на DEV или STAGE среде это приложение может быть всего в одном экземпляре.
--

[autoslide=60000]
=== When to use Core NATS footnote:[https://docs.nats.io/using-nats/developer/develop_jetstream#when-to-use-core-nats]
> Using core NATS is ideal for the fast request path for scalable services where there is tolerance for message loss or when applications themselves handle message delivery guarantees.

[.text-left]
--
These include:

* Service patterns where there is a tightly coupled request-reply where app handle error cases upon timeout

WARNING: Relying on a messaging system to resend here is
considered an *anti-pattern*

* Where only the last message received is important and new messages will
be received frequently enough for applications to tolerate a lost message.
* Message TTL is low
* The expected consumer set for a message is available a-priori and consumers
are expected to be live. The request-reply pattern works well here or
consumers can send an application level acknowledgement.
--

[.notes]
--
Когда же можно использовать функционал ЯДРА?

Кор функционал идеален для быстрых запросов для масштабируемых сервисов с допуском потери сообщения или  обеспечения надежности на уровне приложения.

Это включает:

* Сервисный патерн "Тесной-связанности" - Request/Reply - где очевидна потеря сообщения и приложение может отслеживать переотправку сообщения
В нашей микросервисной архитектуре, это ЗЛО, с которым мы должны бороться и рассматривать его использование, только в крайних случаях.

WARNING: Надеяться на то, что NATS будет заниматься переотправкой - это анти-патерн!

[.text-left]
* Когда важно только последнее сообщение и новые сообщения отправляются довольно часто, что бы приложения мерилось с потерей сообщений.
* Время жизни сообщения мало - данные быстро деградируют или быстро становятся не актуальными.
Это могут быть поток рыночных котировок, большой обмен сообщениями в системе контроля сервисами или телеметрия оборудования.
* Потребитель живет а-приори и ожидается, что консьюмер живет.
Я расцениваю это как анти-патерн - т.к. `все что может произойти, произойдет`, исключение - распил монолита. Первая стадия - изоляция компонентов через брокер, тут наш сервис является и подписчиком и продюсером.
--

[autoslide=60000]

[%notitle]
== Quiz

Quiz

== Presentation url
image:pres_url.png[width=500]

== Contacts
icon:envelope[size=lg] d.harupa@pin-up.team

icon:envelope[size=lg] d7561985@gmail.com

icon:github[size=lg] https://github.com/d7561985

icon:linkedin[size=lg] https://linkedin.com/in/dzmitry-harupa-332131137

icon:instagram[size=lg] dzmityinv

== Q/A
